{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNBaPKazCvKMfooGl8U5U7b",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fzanartu/github-slideshow/blob/master/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pu-F5Gu2PQJM",
        "outputId": "768269f5-dce5-441a-b73f-e8c53f855bca"
      },
      "source": [
        "!sudo apt-get install build-essential swig\n",
        "!pip install auto-sklearn==0.11.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.4ubuntu1).\n",
            "swig is already the newest version (3.0.12-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 31 not upgraded.\n",
            "Requirement already satisfied: auto-sklearn==0.11.1 in /usr/local/lib/python3.7/dist-packages (0.11.1)\n",
            "Requirement already satisfied: distributed>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn==0.11.1) (2021.4.0)\n",
            "Requirement already satisfied: ConfigSpace<0.5,>=0.4.14 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn==0.11.1) (0.4.18)\n",
            "Requirement already satisfied: scipy>=0.14.1 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn==0.11.1) (1.4.1)\n",
            "Requirement already satisfied: pynisher>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn==0.11.1) (0.6.4)\n",
            "Requirement already satisfied: smac<0.14,>=0.13.1 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn==0.11.1) (0.13.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from auto-sklearn==0.11.1) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn==0.11.1) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from auto-sklearn==0.11.1) (54.2.0)\n",
            "Requirement already satisfied: liac-arff in /usr/local/lib/python3.7/dist-packages (from auto-sklearn==0.11.1) (2.5.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from auto-sklearn==0.11.1) (3.13)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn==0.11.1) (1.1.5)\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.7/dist-packages (from auto-sklearn==0.11.1) (2.12.0)\n",
            "Requirement already satisfied: pyrfr<0.9,>=0.7 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn==0.11.1) (0.8.1)\n",
            "Requirement already satisfied: scikit-learn<0.23,>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from auto-sklearn==0.11.1) (0.22.2.post1)\n",
            "Requirement already satisfied: lockfile in /usr/local/lib/python3.7/dist-packages (from auto-sklearn==0.11.1) (0.12.2)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.2.0->auto-sklearn==0.11.1) (1.7.0)\n",
            "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.2.0->auto-sklearn==0.11.1) (5.4.8)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.2.0->auto-sklearn==0.11.1) (0.11.1)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.2.0->auto-sklearn==0.11.1) (2.3.0)\n",
            "Requirement already satisfied: tornado>=5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from distributed>=2.2.0->auto-sklearn==0.11.1) (5.1.1)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.2.0->auto-sklearn==0.11.1) (1.0.2)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.2.0->auto-sklearn==0.11.1) (7.1.2)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.2.0->auto-sklearn==0.11.1) (2.0.0)\n",
            "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.2.0->auto-sklearn==0.11.1) (1.6.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from ConfigSpace<0.5,>=0.4.14->auto-sklearn==0.11.1) (0.29.22)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from ConfigSpace<0.5,>=0.4.14->auto-sklearn==0.11.1) (2.4.7)\n",
            "Requirement already satisfied: lazy-import in /usr/local/lib/python3.7/dist-packages (from smac<0.14,>=0.13.1->auto-sklearn==0.11.1) (0.2.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0->auto-sklearn==0.11.1) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0->auto-sklearn==0.11.1) (2.8.1)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2.2.0->auto-sklearn==0.11.1) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from lazy-import->smac<0.14,>=0.13.1->auto-sklearn==0.11.1) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27_DHtpDQbLR",
        "outputId": "7d72d5cf-0c96-44a4-f335-e474546e4463"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx2sKSl1Qb6c"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itJ4rEFYQljA"
      },
      "source": [
        "df = pd.read_csv('/content/domain_tfinal.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQlqQoumSVWL",
        "outputId": "66ed8675-2f80-4156-9ef0-e23af4cfa38c"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "py_file_location = (\"/content/\")\n",
        "sys.path.append(os.path.abspath(py_file_location))\n",
        "import model6\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3foREcmXGW1"
      },
      "source": [
        "df = df[df['Valid Repo'] == True]\n",
        "principal_language_frame = df['Language']\n",
        "principal_language_frame = pd.get_dummies(principal_language_frame).add_prefix('lg: ')\n",
        "\n",
        "license_frame = df['License']\n",
        "license_frame = pd.get_dummies(license_frame).add_prefix('li: ')\n",
        "\n",
        "releases = df['Releases Count']\n",
        "stars = df['Stars']\t\n",
        "forks = df['Forks']\n",
        "\n",
        "# Pre procesing columns to vectorize \n",
        "# Modify datatype from object to string\n",
        "description = df['Description'].apply(str)\n",
        "readme = df['Readme File'].apply(str)\n",
        "topic = df['Topic List'].apply(str)\n",
        "prog_lang = df['Prog. Languages'].apply(str)\n",
        "labels = df['Labels'].apply(str)\n",
        "contributors = df['Contributors'].apply(str)\n",
        "\n",
        "# Obtain labels\n",
        "y = df.Domain"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8I3-hAeXOog",
        "outputId": "b22001d6-4cad-4caa-ab1c-d941386fe958"
      },
      "source": [
        "norm_d = model6.normalize_corpus(description)\n",
        "nlr = model6.remove_links(readme)\n",
        "norm_rm = model6.normalize_corpus(nlr)\n",
        "norm_cn = model6.remove_brackets(contributors)\n",
        "norm_pl = model6.remove_brackets(prog_lang)\n",
        "norm_tp = model6.remove_brackets(topic)\n",
        "blb = model6.remove_brackets(labels)\n",
        "norm_lb = model6.clean_char(blb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4973/4973 [03:27<00:00, 24.02it/s]\n",
            "100%|██████████| 4973/4973 [24:00<00:00,  3.45it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BS7epemqe9kT"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "\n",
        "def vectorize(text, prefix):\n",
        "    vect = CountVectorizer()\n",
        "    text_vectorized = vect.fit_transform(text)\n",
        "    return pd.DataFrame(text_vectorized.toarray(), columns=vect.get_feature_names()).add_prefix(prefix)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlaL35pyfFuw"
      },
      "source": [
        "ds = vectorize(norm_d, 'd: ')\n",
        "rm = vectorize(norm_rm, 'rm: ')\n",
        "vc = vectorize(norm_cn, 'cn: ')\n",
        "vpl = vectorize(norm_pl, 'pl: ')\n",
        "vt = vectorize(norm_tp, 'tp: ')\n",
        "vl = vectorize(norm_lb, 'lb: ')\n",
        "\n",
        "# concatenate vectorized word counts:\n",
        "\n",
        "X_word = pd.concat([ds,rm,vc,vpl,vt,vl],axis=1)\n",
        "X_word.reset_index(drop=True, inplace=True)\n",
        "X_ohe = pd.concat([principal_language_frame, license_frame, releases, stars, forks], axis=1)\n",
        "X_ohe.reset_index(drop=True, inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muTra8btfTKW"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# train 0.6 test 0.4 split\n",
        "# # unbalanced dataset\n",
        "X_train_word, X_test_word, y_train, y_test = train_test_split(X_word, y, random_state=42, test_size= 0.4, stratify=y)\n",
        "X_train_ohe, X_test_ohe = train_test_split(X_ohe, random_state=42, test_size=0.4, stratify = y)\n",
        "\n",
        " \n",
        "# reduce dimension\n",
        "start_time = time.time()\n",
        "X_train_word, X_test_word = model6.dimensionality_reduction(X_train_word, X_test_word, y_train)\n",
        "end_time = time.time()\n",
        "dim_time = end_time - start_time\n",
        "\n",
        "# concatenate bow and dummies\n",
        "X_train = pd.concat([X_train_word,X_train_ohe], axis=1)\n",
        "X_test = pd.concat([X_test_word,X_test_ohe], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WULAITWOfnjN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsslOuGTft2s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}